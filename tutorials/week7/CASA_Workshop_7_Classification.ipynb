
<!-- saved from url=(0112)https://moodle.ucl.ac.uk/pluginfile.php/3936862/mod_resource/content/3/DSSS_2021_Workshop_7_Classification.ipynb -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body data-new-gr-c-s-check-loaded="14.1049.0" data-gr-ext-installed="" style="">{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style="\&quot;float:left\&quot;">\n",
    "    <h1 style="\&quot;width:600px\&quot;">Workshop 7: Classification</h1>\n",
    "    <h3 style="\&quot;width:600px\&quot;">CASA0006: Data Science for Spatial Systems</h3>\n",
    "    <h3 style="\&quot;width:600px\&quot;">Author: Huanfa Chen</h3>\n",
    "</div>\n",
    "<div style="\&quot;float:right\&quot;"><img width="\&quot;100\&quot;" src="./Workshop_7_Classification.ipynb_files/_"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week we will focus on **classification algorithms and applications**.  Classifiers are highly useful in extracting patterns from large datasets. By setting up a classifier on an understood, pre-classified subset of the data, we are able to automatically derive greater understanding into other, unclassified datasets.\n",
    "\n",
    "The process of creating a classifier remains the same no matter which method you use:\n",
    "\n",
    "1. Organise and clean your dataset.\n",
    "2. Divide the dataset into training and testing subsets.\n",
    "3. Use the classifier to associate feature attributes within the training dataset to *known* classifications (known as *training* or *calibration*).\n",
    "4. Test the strength of model fit by predicting the classifications within the test dataset (known as *testing* or *validation*).\n",
    "5. If you are happy with the model performance, you can apply the classifier to any new and future data in order to establish classifications. This provides instant insight into the type of data you are receiving.\n",
    "\n",
    "Once more during this session, we will use Python and specifically the **`pandas`** and **`scikit-learn`** libraries. The method for the application of different classification methods using `sklearn` is helpfully very consistent, as such we will explore a range of different methods today. We will also look at ways to explore the quality of the prediction results, in order to understand how well our mining is going.\n",
    "\n",
    "As usual, we need to import the relevant libraries to get started, so **run the script below** first to give us access to our basic data analysis packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 300) # specifies number of rows to show\n",
    "pd.options.display.float_format = '{:40,.4f}'.format # specifies default number format to 4 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset you'll be working with today relates to the personal characteristics of over 32,000 individuals. Our task is to work out whether we can predict whether an individual's income is above or below $50,000 per annum, based solely on their demographic characteristics. While we are dealing with quite a few attributes here, we're only predicting over two classes, thus it is a relatively straightforward classification problem.\n",
    "\n",
    "**Download the dataset from Github, and import it as a Pandas dataframe called `original_data`. Inspect the dataset, and use the accompanying metadata to help you understand what you have.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data=pd.read_csv('https://raw.githubusercontent.com/huanfachen/Spatial_Data_Science/main/Dataset/income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped="">\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "  \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "  \n",
       "  \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "  \n",
       "<table border="\&quot;1\&quot;" class="\&quot;dataframe\&quot;"><thead><tr style="\&quot;text-align:" right;\"=""><th></th><th>age</th><th>workclass</th><th>fnlwgt</th><th>education</th><th>education-num</th><th>marital-status</th><th>occupation</th><th>relationship</th><th>race</th><th>sex</th><th>capital-gain</th><th>capital-loss</th><th>hours-per-week</th><th>native-country</th><th>over50k</th></tr></thead><tbody><tr><th>0</th><td>39</td><td>State-gov</td><td>77516</td><td>Bachelors</td><td>13</td><td>Never-married</td><td>Adm-clerical</td><td>Not-in-family</td><td>White</td><td>Male</td><td>2174</td><td>0</td><td>40</td><td>United-States</td><td>&lt;=50K</td></tr><tr><th>1</th><td>50</td><td>Self-emp-not-inc</td><td>83311</td><td>Bachelors</td><td>13</td><td>Married-civ-spouse</td><td>Exec-managerial</td><td>Husband</td><td>White</td><td>Male</td><td>0</td><td>0</td><td>13</td><td>United-States</td><td>&lt;=50K</td></tr><tr><th>2</th><td>38</td><td>Private</td><td>215646</td><td>HS-grad</td><td>9</td><td>Divorced</td><td>Handlers-cleaners</td><td>Not-in-family</td><td>White</td><td>Male</td><td>0</td><td>0</td><td>40</td><td>United-States</td><td>&lt;=50K</td></tr><tr><th>3</th><td>53</td><td>Private</td><td>234721</td><td>11th</td><td>7</td><td>Married-civ-spouse</td><td>Handlers-cleaners</td><td>Husband</td><td>Black</td><td>Male</td><td>0</td><td>0</td><td>40</td><td>United-States</td><td>&lt;=50K</td></tr><tr><th>4</th><td>28</td><td>Private</td><td>338409</td><td>Bachelors</td><td>13</td><td>Married-civ-spouse</td><td>Prof-specialty</td><td>Wife</td><td>Black</td><td>Female</td><td>0</td><td>0</td><td>40</td><td>Cuba</td><td>&lt;=50K</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>32556</th><td>27</td><td>Private</td><td>257302</td><td>Assoc-acdm</td><td>12</td><td>Married-civ-spouse</td><td>Tech-support</td><td>Wife</td><td>White</td><td>Female</td><td>0</td><td>0</td><td>38</td><td>United-States</td><td>&lt;=50K</td></tr><tr><th>32557</th><td>40</td><td>Private</td><td>154374</td><td>HS-grad</td><td>9</td><td>Married-civ-spouse</td><td>Machine-op-inspct</td><td>Husband</td><td>White</td><td>Male</td><td>0</td><td>0</td><td>40</td><td>United-States</td><td>&gt;50K</td></tr><tr><th>32558</th><td>58</td><td>Private</td><td>151910</td><td>HS-grad</td><td>9</td><td>Widowed</td><td>Adm-clerical</td><td>Unmarried</td><td>White</td><td>Female</td><td>0</td><td>0</td><td>40</td><td>United-States</td><td>&lt;=50K</td></tr><tr><th>32559</th><td>22</td><td>Private</td><td>201490</td><td>HS-grad</td><td>9</td><td>Never-married</td><td>Adm-clerical</td><td>Own-child</td><td>White</td><td>Male</td><td>0</td><td>0</td><td>20</td><td>United-States</td><td>&lt;=50K</td></tr><tr><th>32560</th><td>52</td><td>Self-emp-inc</td><td>287927</td><td>HS-grad</td><td>9</td><td>Married-civ-spouse</td><td>Exec-managerial</td><td>Wife</td><td>White</td><td>Female</td><td>15024</td><td>0</td><td>40</td><td>United-States</td><td>&gt;50K</td></tr></tbody></table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country over50k  \n",
       "0              2174             0              40  United-States   &lt;=50K  \n",
       "1                 0             0              13  United-States   &lt;=50K  \n",
       "2                 0             0              40  United-States   &lt;=50K  \n",
       "3                 0             0              40  United-States   &lt;=50K  \n",
       "4                 0             0              40           Cuba   &lt;=50K  \n",
       "...             ...           ...             ...            ...     ...  \n",
       "32556             0             0              38  United-States   &lt;=50K  \n",
       "32557             0             0              40  United-States    &gt;50K  \n",
       "32558             0             0              40  United-States   &lt;=50K  \n",
       "32559             0             0              20  United-States   &lt;=50K  \n",
       "32560         15024             0              40  United-States    &gt;50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will notice, the data you have been provided with an indicator stating whether the individual does or does not earn over $50000 per annum. Well we use this indicator to define the relationship between the individual's characteristics and this classification.\n",
    "\n",
    "But to get their, we need to start splitting up our dataset. We need one dataset containing our attribute data, and we need one dataset containing our classifications. We'll eventually pass both of these to the classifier so that it can identify the classification relationship.\n",
    "\n",
    "So first, we will create our attribute dataset. **Create a new dataframe called `data` that includes all attributes from `original_data` except the `over50k` attribute. Remember to check the contents of your new dataframe to ensure this is the case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=original_data.iloc[:, :14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create the label dataset (the `y` variable) by transforming the `over50k` variable into numerics. To do this, we'll use the `LabelEncoder`. This function takes a column of target labels and encode target labels with value between 0 and `n_classes - 1`. A documentation of this function is [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
    "\n",
    "We can later use the same encoder to reverse the encoding.\n",
    "\n",
    "**Run the scripts below to first import the `LabelEncoder` tools, and then create the labels dataset from the `over50k` class column.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() # creates the LabelEncoder object\n",
    "le.fit(['&lt;=50K', '&gt;50K']) # we explicitly encode '&lt;=50k' and '&gt;50k' with 0 and 1, respectively\n",
    "label_y = le.transform(original_data['over50k']) # runs LabelEncoder on the over50k column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the target variable is ready to go. Next, we need to preprocess the X variables and convert them to numericals, as the `sklearn` classification methods do not play well with text variables.\n",
    "\n",
    "We do this by converting each categorical attribute into a range of additional boolean columns representing each category, marked with 1s or 0s. This does not change the structure of the dataset as the boolean values will continue to to distinguish between features.\n",
    "\n",
    "In this case, we use `DictVectorizer`. `DictVectorizer` takes our data as a series of dictionaries, and transforms it into a matrix which is free of categorical data. This function is similar to the `pandas.get_dummies`, although some differences exist. For example, `DictVectorizer` can be integrated into a pipeline in `sklearn` which simplifies the model building, but `pandas.get_dummies` cannot be used with a `sklearn` pipeline.\n",
    "\n",
    "**Run through the following commands.** Starting with importing the `DictVectorizer` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert our attribute data to an array of dictionaries for the `DictVectorizer`. We use the `Pandas.to_dict()` function for this. The `'records'` flag ensures that the attribute dataset is converted into an array of dictionaries, where each dictionary represents a single data record.\n",
    "\n",
    "**Run the script to create the dictionaries, and verify the data by checking the first entry.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we run the `DictVectorizer` to extract the matrix.** This is a very simple procedure, and note below how the commands needed to run this are very similar to those used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()  # create the DictVectorizer object\n",
    "vec_array = vec.fit_transform(data_dict).toarray()  # execute process on the record dictionaries and transform the result into a numpy array object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now check `vec_array` to see how widely the dataset has been expanded (remember it consisted of 14 attributes before).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9000e+01, 2.1740e+03, 0.0000e+00, ..., 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [5.0000e+01, 0.0000e+00, 0.0000e+00, ..., 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [3.8000e+01, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [5.8000e+01, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.2000e+01, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [5.2000e+01, 1.5024e+04, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the feature names by calling the `get_feature_names` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'education-num',\n",
       " 'education=10th',\n",
       " 'education=11th',\n",
       " 'education=12th',\n",
       " 'education=1st-4th',\n",
       " 'education=5th-6th',\n",
       " 'education=7th-8th',\n",
       " 'education=9th',\n",
       " 'education=Assoc-acdm',\n",
       " 'education=Assoc-voc',\n",
       " 'education=Bachelors',\n",
       " 'education=Doctorate',\n",
       " 'education=HS-grad',\n",
       " 'education=Masters',\n",
       " 'education=Preschool',\n",
       " 'education=Prof-school',\n",
       " 'education=Some-college',\n",
       " 'fnlwgt',\n",
       " 'hours-per-week',\n",
       " 'marital-status=Divorced',\n",
       " 'marital-status=Married-AF-spouse',\n",
       " 'marital-status=Married-civ-spouse',\n",
       " 'marital-status=Married-spouse-absent',\n",
       " 'marital-status=Never-married',\n",
       " 'marital-status=Separated',\n",
       " 'marital-status=Widowed',\n",
       " 'native-country=?',\n",
       " 'native-country=Cambodia',\n",
       " 'native-country=Canada',\n",
       " 'native-country=China',\n",
       " 'native-country=Columbia',\n",
       " 'native-country=Cuba',\n",
       " 'native-country=Dominican-Republic',\n",
       " 'native-country=Ecuador',\n",
       " 'native-country=El-Salvador',\n",
       " 'native-country=England',\n",
       " 'native-country=France',\n",
       " 'native-country=Germany',\n",
       " 'native-country=Greece',\n",
       " 'native-country=Guatemala',\n",
       " 'native-country=Haiti',\n",
       " 'native-country=Holand-Netherlands',\n",
       " 'native-country=Honduras',\n",
       " 'native-country=Hong',\n",
       " 'native-country=Hungary',\n",
       " 'native-country=India',\n",
       " 'native-country=Iran',\n",
       " 'native-country=Ireland',\n",
       " 'native-country=Italy',\n",
       " 'native-country=Jamaica',\n",
       " 'native-country=Japan',\n",
       " 'native-country=Laos',\n",
       " 'native-country=Mexico',\n",
       " 'native-country=Nicaragua',\n",
       " 'native-country=Outlying-US(Guam-USVI-etc)',\n",
       " 'native-country=Peru',\n",
       " 'native-country=Philippines',\n",
       " 'native-country=Poland',\n",
       " 'native-country=Portugal',\n",
       " 'native-country=Puerto-Rico',\n",
       " 'native-country=Scotland',\n",
       " 'native-country=South',\n",
       " 'native-country=Taiwan',\n",
       " 'native-country=Thailand',\n",
       " 'native-country=Trinadad&amp;Tobago',\n",
       " 'native-country=United-States',\n",
       " 'native-country=Vietnam',\n",
       " 'native-country=Yugoslavia',\n",
       " 'occupation=?',\n",
       " 'occupation=Adm-clerical',\n",
       " 'occupation=Armed-Forces',\n",
       " 'occupation=Craft-repair',\n",
       " 'occupation=Exec-managerial',\n",
       " 'occupation=Farming-fishing',\n",
       " 'occupation=Handlers-cleaners',\n",
       " 'occupation=Machine-op-inspct',\n",
       " 'occupation=Other-service',\n",
       " 'occupation=Priv-house-serv',\n",
       " 'occupation=Prof-specialty',\n",
       " 'occupation=Protective-serv',\n",
       " 'occupation=Sales',\n",
       " 'occupation=Tech-support',\n",
       " 'occupation=Transport-moving',\n",
       " 'race=Amer-Indian-Eskimo',\n",
       " 'race=Asian-Pac-Islander',\n",
       " 'race=Black',\n",
       " 'race=Other',\n",
       " 'race=White',\n",
       " 'relationship=Husband',\n",
       " 'relationship=Not-in-family',\n",
       " 'relationship=Other-relative',\n",
       " 'relationship=Own-child',\n",
       " 'relationship=Unmarried',\n",
       " 'relationship=Wife',\n",
       " 'sex=Female',\n",
       " 'sex=Male',\n",
       " 'workclass=?',\n",
       " 'workclass=Federal-gov',\n",
       " 'workclass=Local-gov',\n",
       " 'workclass=Never-worked',\n",
       " 'workclass=Private',\n",
       " 'workclass=Self-emp-inc',\n",
       " 'workclass=Self-emp-not-inc',\n",
       " 'workclass=State-gov',\n",
       " 'workclass=Without-pay']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final stage in data processing involves splitting the prepared dataset into training and testing subsets. The training data will be used to create the classifier. The testing data will then be used to test the accuracy of a the classification. \n",
    "\n",
    "**IMPORTANT**: Splitting the dataset up in this way is an important step. It tests how well the classifier performs against data it hasn't yet seen. This gives a good picture of how well the classifier may work in future. However, remember that we are drawing both training and testing data from the same sample, and so future datasets may not align with the same biases.\n",
    "\n",
    "Once more, we have a useful tool is `scikit` to do this. The `train_test_split` method (surprisingly named) randomly splits our attribute and label data into training and testing subsets. Not only does this provide us with  formats to be loaded directly into our classifers, but the random split ensures a good mixing of the records. \n",
    "\n",
    "The process is quite straightforward. **We load in the `train_test_split` method and run it against our attribute and label arrays.**\n",
    "\n",
    "Note: `train_test_split` will split the data according to a 75:25 split, roughly in line with convention. However, other proportions can be specified, check out the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d, test_d, train_lab, test_lab = train_test_split(vec_array, label_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the lengths of the training and testing datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24420, 8141, 24420, 8141)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_d),len(test_d),len(train_lab),len(test_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start creating our classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbour Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first classifier will use is the *k*-Nearest Neighbour (*k*NN) classifier. This is a very simple method by which tested points are classified according to their proximity (in terms of attribute distance) to points that were seen during training. \n",
    "\n",
    "In this section, we will show you how to use the *k*NN classifer in `scikit`, as well as going into detail about how you can assess the quality of the classification as part of your validation.\n",
    "\n",
    "**IMPORTANT**: Many of the `scikit` classification methods use a very similar syntax. We will show you how to use *k*NN, but you will have to work out how to use the others. On completion, we expect you to be able to say which of the four classifiers you will test performs best in predicting whether the individuals in our test dataset earn more or less than $50k per annum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across all `scikit` classifiers, a similar process and form of syntax is used. \n",
    "\n",
    "1. First, we load the library. \n",
    "2. Then, we create the classifier object, and specify any important parameters.\n",
    "3. We run the `.fit()` method, sending the classifier our training dataset and accompanying labels.\n",
    "4. We analyse the validate with the `.score()` method, sending the classifier our testing dataset and accompanying labels.\n",
    "\n",
    "Let's work through this method for the *k*NN classifer.\n",
    "\n",
    "**First, we import the relevant library from `scikit`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the classifier object and give it a name (`knn` in our case), and run it. \n",
    "\n",
    "On creating the object, we specify any important parameters. To understand what parameters are needed requires understanding the method and the syntax. It is worth you reading the `scikit` documentation on *k*NN at this point, which will provide you details on how to execute the method. \n",
    "\n",
    "[This page](http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification) is a general description of the method. Whereas [this page](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) outlines all of the parameters and methods associated with the `KNeighborsClassifier` method. You'll need to check the documentation for any classifer you use.\n",
    "\n",
    "As you will recall, an important element of the *k*NN approach is the specification of how many neighbours to consider when making the classification. You can see below how this parameter is defined.\n",
    "\n",
    "You'll see from the script below that running this process is very similar to the creation of clusters and regression models last week. **Before you run the script, add in a script to time how long the `.fit()` takes to execute, you'll do the same with other classifiers by way of comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=60)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add timing script\n",
    "knn = KNeighborsClassifier(n_neighbors=60)  # creates the kNN classifier, setting it to check the 60 neighbouring points\n",
    "knn.fit(train_d, train_lab)  # executes the classifier on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, we test how well the classifier predicts the classes of our test dataset. For this stage, we send the test data and labels to the `.score()` function. This outputs a number representing the proportion of classes correctly guessed by the classifer. It requires you to pass it both the test data and test labels.\n",
    "\n",
    "**Run the script below to see how well *kNN* performs in this case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904434344675101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_d, test_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done, you've created and tested a classifer. And the classifier seems to do pretty well. In any future event, given a load more data we'll be able to predict the salary class of an individual with an expected accuracy of 79%, right? Well, hold on there, we better do some further tests just to check how good this score actually is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of other important ways to assess the quality of your classifier that you should be aware of.\n",
    "\n",
    "First, you can have a look yourself at the actual results, and identify the records where predictions succeed and fail. You can do this by generating a set of predictions for each record, done using the `.predict()` method. Like `.score()`, this generates classes for a test dataset, but does take a set of labels. You will use this method in classifying any future unlabelled dataset you wish to classify.\n",
    "\n",
    "**The predictions are recorded within an array using the script below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at `predictions`, however, you'll find just 0s and 1s, as these relate to the outputs generated by `LabelEncoder` earlier. What we need to do is convert these back to the original label data. We do this using the `le.inverse_transform` command. We then convert this into a list, and eventually into a Dataframe for easier manipulation. \n",
    "\n",
    "**Look at the code below and execute it to produce an ordered list of predicted classifications for the `test_d` dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(list(le.inverse_transform(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have this dataset, we want to explore how the predictions vary with the data. We will firstly do this manually (as a practice), and then use the `sklearn.metrics` library to achieve this automatically.\n",
    "\n",
    "A manual way to explore the predictions: **first, run the label decoder again on the test labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped="">\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "  \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "  \n",
       "  \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "    \n",
       "  \n",
       "<table border="\&quot;1\&quot;" class="\&quot;dataframe\&quot;"><thead><tr style="\&quot;text-align:" right;\"=""><th></th><th>0</th></tr></thead><tbody><tr><th>0</th><td>&lt;=50K</td></tr><tr><th>1</th><td>&lt;=50K</td></tr><tr><th>2</th><td>&lt;=50K</td></tr><tr><th>3</th><td>&lt;=50K</td></tr><tr><th>4</th><td>&lt;=50K</td></tr><tr><th>...</th><td>...</td></tr><tr><th>8136</th><td>&lt;=50K</td></tr><tr><th>8137</th><td>&lt;=50K</td></tr><tr><th>8138</th><td>&lt;=50K</td></tr><tr><th>8139</th><td>&lt;=50K</td></tr><tr><th>8140</th><td>&lt;=50K</td></tr></tbody></table>\n",
       "<p>8141 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     &lt;=50K\n",
       "1     &lt;=50K\n",
       "2     &lt;=50K\n",
       "3     &lt;=50K\n",
       "4     &lt;=50K\n",
       "...     ...\n",
       "8136  &lt;=50K\n",
       "8137  &lt;=50K\n",
       "8138  &lt;=50K\n",
       "8139  &lt;=50K\n",
       "8140  &lt;=50K\n",
       "\n",
       "[8141 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next join the predicted classifications to the actual labels (from the test data) to create a new dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.DataFrame(list(le.inverse_transform(test_lab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.rename(columns={0: 'over50k'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, create a new column in the joined dataframe indicating whether the two label values match (check out the `.apply()` function).** You may need to rename your columns in order to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.concat([test_data,predicted],axis=1)\n",
    "result.rename(columns={0: 'predicted'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped="">\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "  \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "  \n",
       "  \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "    \n",
       "      \n",
       "      \n",
       "      \n",
       "    \n",
       "  \n",
       "<table border="\&quot;1\&quot;" class="\&quot;dataframe\&quot;"><thead><tr style="\&quot;text-align:" right;\"=""><th></th><th>over50k</th><th>predicted</th></tr></thead><tbody><tr><th>0</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>1</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>2</th><td>&gt;50K</td><td>&lt;=50K</td></tr><tr><th>3</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>4</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>...</th><td>...</td><td>...</td></tr><tr><th>8136</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>8137</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>8138</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>8139</th><td>&lt;=50K</td><td>&lt;=50K</td></tr><tr><th>8140</th><td>&lt;=50K</td><td>&lt;=50K</td></tr></tbody></table>\n",
       "<p>8141 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     over50k predicted\n",
       "0      &lt;=50K     &lt;=50K\n",
       "1      &lt;=50K     &lt;=50K\n",
       "2       &gt;50K     &lt;=50K\n",
       "3      &lt;=50K     &lt;=50K\n",
       "4      &lt;=50K     &lt;=50K\n",
       "...      ...       ...\n",
       "8136   &lt;=50K     &lt;=50K\n",
       "8137   &lt;=50K     &lt;=50K\n",
       "8138   &lt;=50K     &lt;=50K\n",
       "8139   &lt;=50K     &lt;=50K\n",
       "8140   &lt;=50K     &lt;=50K\n",
       "\n",
       "[8141 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column of 'match' that indicates whether the prediction is correct\n",
    "result['match']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match as True if the prediction is correct, otherwise as False\n",
    "for i,data in result.iterrows():\n",
    "    if data['over50k']==data['predicted']:\n",
    "        data['match']=True\n",
    "    else:\n",
    "        False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7904434344675101"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy rate\n",
    "print('The accuracy rate is: ')\n",
    "len(result.loc[result.match==True])/len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have reinvented the 'wheel' of calculating the accuracy, which is not an easy job. In practice, we can utilise the `sklearn.metrics` library to check the classification result. This toolkit provides a range of measures relating to the predictive power of your classifier. \n",
    "\n",
    "A nice and simple exploratory tool is a confusion matrix. This describes the the extents to which each class was correctly and incorrectly classified. It is generated using the `confusion_matrix()` method, which takes the correct and predicted results. These can then be nicely visualised using the `matplotlib` matrix plotting functions.\n",
    "\n",
    "**First, calcuating the accuracy score using the `metrics.accuracy_score` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation accuracy: \n",
      "0.7904434344675101\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Classifcation accuracy: \")\n",
    "print(metrics.accuracy_score(test_lab, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second, create the matrix and inspect it - what can you derive from this?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(test_lab, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, create the confusion matrix. Does this seem clearer? Where is the majority of the error in the classification?** You can read more about the confusion matrix [here](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<figure size="" 288x288="" with="" 2="" axes="">"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(confusion_matrix)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these measures above provide an overview of the classifier quality, other measures made available in the `metrics` toolset enable a more detailed understanding. Many of the most important measures can be extracted using the `classification_report()` method, which again takes correct labels and compares them against the classifier predictions.\n",
    "\n",
    "These metrics, called `precision`, `recall` and `f1`, all measure how well a classifier does in predicting each class relative to how often it is incorrect. As such, it allows us to identify the prediction classes where it performs well and where it performs poorly.\n",
    "\n",
    "**Before executing the code below, look at the [documentation](http://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules) here to gain a little understanding of these measures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      6165\n",
      "           1       0.94      0.15      0.25      1976\n",
      "\n",
      "    accuracy                           0.79      8141\n",
      "   macro avg       0.86      0.57      0.56      8141\n",
      "weighted avg       0.82      0.79      0.73      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification results: \")\n",
    "print(metrics.classification_report(test_lab, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result provides a lot of insights into the classification. For example:\n",
    "\n",
    "1. How many indivudlas are correctly classified regardless of their actual class? (Hint: accuray, 79.5%) \n",
    "1. How many individuals with incomes over 50K are correctly recognised by the classifier? (Hint: recall, 14%)\n",
    "1. Out of all individuals that are classified as earning over 50K, how many of them actually have an income higher than 50K? (Hint: precision, 92%)\n",
    "\n",
    "The most striking of these results is that the classifier performs very poorly in identifying individuals earning over 50,000 per annum, which is indicated by the very low recall score. For class of `over50K`, the recall is 0.14, which means that only 14 out of 100 individuals earning over $50,000 are correctly recognised by the kNN classifier.\n",
    "\n",
    "**This should be a concern to us**.\n",
    "\n",
    "In the real world, you would consider two potential actions in response to findings like these:\n",
    "\n",
    "1. Change the sample data by adding more individuals of `over50K`;\n",
    "2. Recreate the classifier using a different set of hyperparameters (aka, hyperparameter tuning);\n",
    "3. Use a different classifier to see if it leads to better results;\n",
    "\n",
    "Next, we will try other classifiers to see whether we can get a higher classification accuracy or recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method that we will try is the Decision Tree. \n",
    "\n",
    "The Decision Tree does not (necessarily) require any parameters when being setup so is quite easy to implement, just follow the same method and syntax used above. In this case, however, you'll be working with  `DecisionTreeClassifier` rather than `KNeighborsClassifier`.\n",
    "\n",
    "Before you start, check the [documentation](http://scikit-learn.org/stable/modules/tree.html#classification) here.\n",
    "\n",
    "**Now create a Decision Tree classifier for the same scenario and datasets used earlier** (you don't need to recreate the datasets, they are good to go already). We've given you the library import code below to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(train_d, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129222454243951"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(test_d, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree.predict(test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(list(le.inverse_transform(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(test_lab, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<figure size="" 288x288="" with="" 2="" axes="">"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(confusion_matrix)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      6165\n",
      "           1       0.61      0.62      0.62      1976\n",
      "\n",
      "    accuracy                           0.81      8141\n",
      "   macro avg       0.75      0.75      0.75      8141\n",
      "weighted avg       0.81      0.81      0.81      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(test_lab, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Work through the stages used during the creation of the *k*-Nearest Neighbour classifier, and identify whether the Decision Tree outperforms this *k*NN approach or not.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, carry out the same process using a Random Forest classifier.\n",
    "\n",
    "Unlike the Decision Tree, the Random Forest requires you to specify a parameter called `n_estimators`. This parameter specifies how many trees should be created in the construction of the whole forest. The more trees you choose, the longer the classification process will take to run.\n",
    "\n",
    "So first, read up on the `scikit` Random Forest method [here](http://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees), and identify how you can set the `n_estimators` parameter and then follow through the same classifier creation and testing process used above.\n",
    "\n",
    "**How well does this model perform relative to the Decision Tree and *k*-Nearest Neighbour approaches? How does varying the number of trees impact on the quality and speed of prediction?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train_d,train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.843631003562216"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the score function can be used to make predictions on a new dataset and then to calculate the accuracy score.\n",
    "forest.score(test_d, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest.predict(test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(test_lab, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<figure size="" 288x288="" with="" 2="" axes="">"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(confusion_matrix)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      6165\n",
      "           1       0.73      0.57      0.64      1976\n",
      "\n",
      "    accuracy                           0.84      8141\n",
      "   macro avg       0.80      0.75      0.77      8141\n",
      "weighted avg       0.84      0.84      0.84      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(test_lab, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learinng, hyperparameters are model settings that control the learning process (e.g. number of trees in a random forest). They should be distinguished from **parameters** that are automatically learnt in the model training process (e.g. splits in a tree of a random forest).\n",
    "\n",
    "Hyperparameters need to be predefined before model training. Normally, the packages that we use provide default value for hyperparameters. For example, if we create a `RandomForestClassifier` without specifying n_estimator, the number of trees (aka `n_estimators`) is set as 100 by default. More details can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "Some of you may ask how to find the optimal number of trees for a random forest. There is no perfect answer for this question. A rule of thumb is that the more trees, the smaller variance in the classification result and the higher computation cost (e.g. memory and time). \n",
    "\n",
    "Here, we are interested to test whether we can find a better value for the number of trees. We would like to test a range of values, namely 50, 100, 200, 300, 400. Again, choosing these values is kind of subjective.\n",
    "\n",
    "We will use the grid search and 5-fold cross validation to tune this hyperparameter.\n",
    "\n",
    "An illustration of k-fold cross validation is as follows:\n",
    "\n",
    "![](https://github.com/huanfachen/Spatial_Data_Science/raw/main/Images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at how to do cross validation in `sklearn`. There are different ways to do this in `sklearn`, and one of these is calling the `cross_val_score` function, which evaluates a score using cross validation. The documentation is [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html).\n",
    "\n",
    "Here we focus on the accuracy score. So, run the following code to use cross validation for a random forest classifier (with 10 trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8478706  0.85012285 0.8470516  0.8495086  0.84807535]\n",
      "Accuracy: 0.85 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# number of fold as 5\n",
    "cv_fold=5\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# call the cross_val_score function\n",
    "scores = cross_val_score(clf, train_d, train_lab, cv=cv_fold)\n",
    "# note that this is an array\n",
    "print(scores) \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result contains a list of five accuracy scores, each of which is generated by training a classifier on four folds and testing the classifier on the other fold. Then, the avearge and standard deviation of the accuracy scores is calculated and printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we use the 5-fold cross validation and grid search to tune the `n_estimators`. Grid search is an exhaustive search procedure over specified parameter values for an estimator. \n",
    "\n",
    "We will use the **GridSearchCV** function from the `sklearn` library. This function integrates the grid search and cross validation procedure. Its documentation is [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "Run the following code to do GridSearchCV. This process may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'n_estimators': [50, 100, 200, 300, 400]})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# values of n_estimators\n",
    "parameters = {'n_estimators':[50, 100, 200, 300, 400]}\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "clf = model_selection.GridSearchCV(rf, parameters)\n",
    "\n",
    "clf.fit(train_d, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter value is: \n",
      "{'n_estimators': 300}\n",
      "The best score is: \n",
      "0.8581081081081081\n"
     ]
    }
   ],
   "source": [
    "# we can query the best parameter value and its accuracy score\n",
    "print (\"The best parameter value is: \")\n",
    "print (clf.best_params_)\n",
    "print (\"The best score is: \")\n",
    "print (clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my computer, it says that the best n_estimators value is **300**. The result indicates that the default `n_estimators` value (**100**) is not optimal. Note that this might be subject to randomisation, which means you could get a different result after you run the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Conclusion..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we have practiced several algorithms for classification and different techniques for building a classification models (e.g. splitting training and testing data, cross validation, grid search, hyperparameter tuning). Please be aware that these techniques are not restricted to classification models. They are widely applicable for supervised learning tasks in machine learning, e.g. regression.\n",
    "\n",
    "There are a few challenges that I want you to explore. Go on, give at least one of them a go.\n",
    "\n",
    "- Try to compare the results of different classification algorithms using different metrics (e.g. accuracy, precision, recall, F1). Which algorithm is the best?\n",
    "- Try to tune the **k** hyperparameter in kNN. Which k leads to the highest accuracy?\n",
    "- Implement logistic regression and artificial neural network for this task. The functions are available in sklearn and their use is similar to kNN and random forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sds2020",
   "language": "python",
   "name": "sds2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
</figure></figure></figure></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>